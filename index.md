## Rajendra Jadi  
rajendrayjadi@gmail.com 704-241-4674 https://www.linkedin.com/in/rjadi/ https://github.com/RajendraJadi
Software Engineer with programming experience of 3+ years. Seeking full time opportunities in Software Engineering, Data Engineering.

Technical skills
------------ | -------------
• Python, SQL, Java, Scala, C++ | • Linux, Natural Language Processing
• Hadoop, MapReduce, Spark, Hive, Solr | • AWS (S3, EC2, EMR), Google Cloud
• HiveQL, PostgreSQL, Teradata, MySQL | • Javascript, php, Git, Docker, Tableau Work Experience

### Data Engineer (Internship), Relishly Inc, Santa Clara, CA June 2018- Aug 2018
A technology startup that builds AI platform to enrich shopping experiences for e-commerce stores, retailers, comparison shopping engines.
Development (Python | Linux | Shell | Apache Beam | Solr | Google Cloud)
• Built Data pipelines using Apache Beam to analyze real time logs of e-commerce website to create analytics indexing the data in Solr.
• Implemented trending algorithm to find trendiness of items for the e-commerce platform using rolling z-score.
• Developed API for dashboard to pull data from Solr.
• Automated backup of Solr collections from Solr to Google storage.
• Automated the solr, zookeeper cluster setup in google cloud and implemented disaster recovery during downtime.

### Software Engineer, Tesco PLC, India July 2014 – July 2017
The multinational Supply chain and general merchandise retailer.
Development (Linux| Java | Hadoop | Hive | SQL | Spark | Teradata | ETL)
• Developed and implemented the complex ETL solution for Group Promotional Forecasting model for store appliance which provides near real time accurate promotion forecasting to deliver availability, waste and stockholding benefits.
• Implemented MapReduce paradigm in conjunction with Apache Hadoop to parallelly execute complex operation on Big data, increasing the overall performance by 20%.
• Developed a framework from Teradata to Hadoop using SQOOP for live Archival of data, which helped in making better decisions due to availability of huge data.
• Built an automation tool to perform functional testing, QA testing, referential integrity checks using Java and Teradata stored procedures to automate routine tasks.
• Automated batch monitoring and testing activities utilizing shell scripting and python programming to drive automation, reducing manual efforts by 30%.

### Education
Master’s Degree, Computer Science (3.75/4.00) University of North Carolina at Charlotte Expected Graduation: December 2018
Courses: Parallel Computing, Machine-Learning, Cloud Computing, Natural Language Processing, Big Data analytics
Bachelor’s Degree, Information Science (8.00/10) Visvesvaraya Technological University, India Aug 2010 – Jun 2014
Courses: Software Engineering, Data warehousing and Data mining, Business Intelligence, Databases, Web Development 

### Research/Academic Projects
Software Engineering: Classification of Facebook news feeds and Sentiment analysis - Developed a tool that extracts real-time data, classifies the Facebook user’s news feeds into various categories using classifiers like Naïve Bayes, SVM, Logistic Regression and perform sentiment analysis on facebook news feeds. Publication: International Conference on Advances in Computing, Communications and Informatics
Parallel Programming: Implemented parallel algorithms using pthreads, openMP, MPI and analyzed speedup of various algorithms.
Natural Language Processing: Built a classifier in Python to classify 2016 Presidential debate using Multinomial Naive Bayes Classifier and Support Vector Classifier. Increased accuracy of classifier by 2.5%. Implemented Language Model and spell checker in python.
Machine Learning: Regression, Clustering, Classification, Forecasting, Support Vector Machines and Artificial Neural Network on various datasets and tested the models against various tests to decide the correctness of the model using Python.
Data Mining: Independent Research Project - Implementing Action Rules for Sentiment analysis on Twitter data using Spark.
Indexed Wikipedia dataset using Elastic search, Solr in AWS and Google cloud.
Web Development: Research Assistant - Developed frond end components using PHP, HTML & javascript in Laravel framework. Fabricated the interface of website using HTML, CSS, JavaScript and JQuery.
Other Technologies: Shell Scripting, Scala, Git, Ab Initio, ETL, HDFS, Oozie, Yarn, NLTK, Numpy, Pandas, Sci-kit learn, Git, TensorFlow, Anaconda, Docker, Tableau, Linux, Microsoft Windows, XML, JSON, Unit testing, Pytest, Performance testing.
Website: https://rajendrajadi.github.io/|
